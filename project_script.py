import json
import os
import time
from openai import OpenAI # å¼•å…¥å®˜æ–¹æ¨èçš„OpenAIåº“

# --- 1. é…ç½®åŒºåŸŸ ---
IMAGE_DIR = r"D:\ppttry\output\ppt_images"
WHISPER_JSON_PATH = r"D:\ppttry\output\transcript\output_audio.json"
OUTPUT_MD_PATH = r"D:\ppttry\output\final_note_optimized.md"
IMAGE_PATH_PREFIX = "./ppt_images/"

# --- å¤§è¯­è¨€æ¨¡å‹APIé…ç½® (æ ¹æ®å®˜æ–¹æ–‡æ¡£æ›´æ–°) ---
# ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–APIå¯†é’¥
API_KEY = os.getenv("SILICON_CLOUD_API_KEY") 
# ä½¿ç”¨å®˜æ–¹æ–‡æ¡£æŒ‡å®šçš„æ­£ç¡®APIåœ°å€
BASE_URL = "https://api.siliconflow.cn/v1"
MODEL_NAME = "Qwen/Qwen3-30B-A3B-Thinking-2507" # ä½ æŒ‡å®šçš„æ¨¡å‹

PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™å­¦ç¬”è®°æ•´ç†åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¤„ç†ä¸€æ®µæ•™å¸ˆè¯¾å ‚æ•™å­¦çš„åŸå§‹å£è¯­å½•éŸ³ç¨¿ï¼Œå°†å…¶è½¬åŒ–ä¸ºä¹¦é¢åŒ–çš„ã€æµç•…ä¸”ç»“æ„æ¸…æ™°çš„æ–‡å­—ã€‚è¯·ä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š

1.  **åˆ é™¤æ‰€æœ‰æ— æ„ä¹‰çš„è¯­æ°”è¯ã€å£å¤´ç¦…å’Œé‡å¤**ï¼šä¾‹å¦‚â€œå—¯â€ã€â€œå•Šâ€ã€â€œé‚£ä¸ªâ€ã€â€œå°±æ˜¯è¯´â€ã€â€œå¯¹å§â€ã€â€œæ˜¯å§â€ç­‰ã€‚
2.  **ä¿®æ­£æ˜æ˜¾çš„å£è¯¯å’Œè¯­æ³•é”™è¯¯**ï¼šå°†é¢ å€’çš„è¯åºè°ƒæ•´é€šé¡ºï¼Œè¡¥å…¨å¥å­æˆåˆ†ï¼Œä½¿å…¶ç¬¦åˆä¹¦é¢è¯­è§„èŒƒã€‚
3.  **ä¿æŒæ•™å¸ˆçš„åŸæ„å’Œä¸“ä¸šæœ¯è¯­**ï¼šç»å¯¹ä¸è¦è¿›è¡Œå†…å®¹ä¸Šçš„æ€»ç»“ã€ç¼©å†™æˆ–ä¸ªäººè§£è¯»ã€‚æ ¸å¿ƒç›®æ ‡æ˜¯â€œæ¶¦è‰²â€è€Œéâ€œåˆ›ä½œâ€ã€‚
4.  **è¾“å‡ºæ•´ç†åçš„çº¯æ–‡æœ¬**ï¼šä¸éœ€è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è¯„è®ºã€æ ‡é¢˜ã€å‰è¨€æˆ–ç»“è¯­ï¼Œç›´æ¥è¾“å‡ºç²¾ç‚¼åçš„æ®µè½ã€‚

ä¸‹é¢æ˜¯éœ€è¦ä½ å¤„ç†çš„åŸå§‹è®²ç¨¿ï¼š
---
{raw_speech}
"""

# --- 2. è¾…åŠ©å‡½æ•° ---
def filename_to_seconds(filename):
    base_name = os.path.splitext(filename)[0]
    clean_name = base_name.rstrip('-')
    parts = clean_name.split('.')
    if len(parts) != 3:
        raise ValueError(f"Filename '{filename}' does not match expected HH.MM.SS format.")
    hours, minutes, seconds = map(int, parts)
    return float(hours * 3600 + minutes * 60 + seconds)

# --- æ–°å¢ï¼šä½¿ç”¨OpenAIåº“è°ƒç”¨Qwenæ¨¡å‹çš„å‡½æ•° (å®Œå…¨é‡å†™) ---
def optimize_text_with_qwen(client, text_to_optimize):
    if not text_to_optimize:
        return "" # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œç›´æ¥è¿”å›ç©ºå­—ç¬¦ä¸²
    
    final_prompt = PROMPT_TEMPLATE.format(raw_speech=text_to_optimize)
    
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "user", "content": final_prompt}
            ],
            temperature=0.3,
            stream=False # æˆ‘ä»¬éœ€è¦ä¸€æ¬¡æ€§è·å¾—å®Œæ•´ç»“æœï¼Œæ‰€ä»¥ä¸ä½¿ç”¨stream
        )
        optimized_text = response.choices[0].message.content
        return optimized_text.strip()
    
    except Exception as e:
        print(f"\nè°ƒç”¨APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return f"ã€APIè°ƒç”¨å¤±è´¥ï¼Œä¿ç•™åŸå§‹æ–‡æœ¬ã€‘: {text_to_optimize}"

# --- 3. ä¸»é€»è¾‘ ---
def main():
    print("--- æ­¥éª¤ 1: è¯»å–å¹¶æ’åºPPTå›¾ç‰‡æ—¶é—´æˆ³ ---")
    try:
        image_files = [f for f in os.listdir(IMAGE_DIR) if f.lower().endswith('.jpg')]
        ppt_timestamps = sorted([(filename_to_seconds(f), f) for f in image_files])
    except (FileNotFoundError, ValueError) as e:
        print(f"å¤„ç†å›¾ç‰‡ç›®å½•æ—¶å‡ºé”™: {e}")
        return
    if not ppt_timestamps:
        print("é”™è¯¯ï¼šæœªæ‰¾åˆ°æœ‰æ•ˆå›¾ç‰‡æ–‡ä»¶ã€‚")
        return
    print(f"æˆåŠŸè¯»å–å¹¶æ’åºäº† {len(ppt_timestamps)} å¼ PPTå›¾ç‰‡ã€‚")

    print("\n--- æ­¥éª¤ 2: è¯»å–Whisperç”Ÿæˆçš„æ–‡ç¨¿ ---")
    try:
        with open(WHISPER_JSON_PATH, 'r', encoding='utf-8') as f:
            whisper_data = json.load(f)
    except FileNotFoundError:
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°Whisperçš„JSONæ–‡ä»¶ã€‚")
        return
    video_duration = whisper_data['segments'][-1]['end']

    print("\n--- æ­¥éª¤ 3: åŒ¹é…PPTä¸æ•™å¸ˆè®²ç¨¿ ---")
    notes = []
    for i, (ppt_start_time, ppt_filename) in enumerate(ppt_timestamps):
        ppt_end_time = ppt_timestamps[i+1][0] if i + 1 < len(ppt_timestamps) else video_duration
        speech_text = "".join(word_info['word'] for segment in whisper_data['segments'] if 'words' in segment for word_info in segment['words'] if ppt_start_time <= word_info['start'] < ppt_end_time)
        timestamp_str = os.path.splitext(ppt_filename)[0].rstrip('-').replace('.', ':')
        notes.append({"ppt_path": ppt_filename, "timestamp_str": timestamp_str, "speech": speech_text.strip()})
        print(f"å·²åŒ¹é…PPT {ppt_filename}...")
    
    print("\n--- æ–°å¢æ­¥éª¤: è°ƒç”¨å¤§æ¨¡å‹ä¼˜åŒ–è®²ç¨¿æ–‡æœ¬ ---")
    if not API_KEY:
        print("è­¦å‘Šï¼šæœªè®¾ç½® SILICON_CLOUD_API_KEY ç¯å¢ƒå˜é‡ï¼Œå°†è·³è¿‡æ–‡æœ¬ä¼˜åŒ–æ­¥éª¤ã€‚")
    else:
        # åªéœ€åˆ›å»ºä¸€æ¬¡å®¢æˆ·ç«¯
        client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
        for i, note in enumerate(notes):
            print(f"æ­£åœ¨ä¼˜åŒ–ç¬¬ {i+1}/{len(notes)} æ®µæ–‡æœ¬...")
            if note['speech']:
                optimized_speech = optimize_text_with_qwen(client, note['speech'])
                note['speech'] = optimized_speech
                time.sleep(1) # ä¿ç•™1ç§’çš„è¯·æ±‚é—´éš”ï¼Œä¿æŠ¤API
            else:
                print("æ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡ä¼˜åŒ–ã€‚")

    print("\n--- æ­¥éª¤ 4: ç”Ÿæˆæœ€ç»ˆçš„ç²¾ç‚¼ç‰ˆMarkdownç¬”è®° ---")
    with open(OUTPUT_MD_PATH, 'w', encoding='utf-8') as f:
        f.write("# æ•™å­¦è§†é¢‘å­¦ä¹ ç¬”è®° (ç²¾ç‚¼ç‰ˆ)\n\n---\n\n")
        for i, note in enumerate(notes):
            f.write(f"## Slide {i+1} (æ—¶é—´ç‚¹: {note['timestamp_str']})\n\n")
            image_md_path = os.path.join(IMAGE_PATH_PREFIX, note['ppt_path']).replace("\\", "/")
            f.write(f"![Slide {i+1}]({image_md_path})\n\n")
            f.write(f"> {note['speech'] or '(æ­¤æ—¶é—´æ®µå†…æ— æ•™å¸ˆè®²ç¨¿)'}\n\n---\n\n")

    print(f"\nğŸ‰ æœ€ç»ˆä»»åŠ¡å®Œæˆï¼ç²¾ç‚¼ç‰ˆç¬”è®°å·²æˆåŠŸç”Ÿæˆäº: {OUTPUT_MD_PATH}")

if __name__ == "__main__":
    main()